{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE - 변이형 오토인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더 - 네트워크는 고차원 입력 데이터를 저차원 표현 벡터로 압축\n",
    "\n",
    "디코더 - 네트워크는 주어진 표현 벡터를 원본 차원으로 다시 압축 해제\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교재 Autoencoder\n",
    "\n",
    "class Autoencoder():\n",
    "    def __init__(self\n",
    "        , input_dim\n",
    "        , encoder_conv_filters\n",
    "        , encoder_conv_kernel_size\n",
    "        , encoder_conv_strides\n",
    "        , decoder_conv_t_filters\n",
    "        , decoder_conv_t_kernel_size\n",
    "        , decoder_conv_t_strides\n",
    "        , z_dim\n",
    "        , use_batch_norm = False\n",
    "        , use_dropout = False\n",
    "        ):\n",
    "\n",
    "        self.name = 'autoencoder'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_size = encoder_conv_kernel_size\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        self.n_layers_encoder = len(encoder_conv_filters)\n",
    "        self.n_layers_decoder = len(decoder_conv_t_filters)\n",
    "\n",
    "        self._build()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _build(self):\n",
    "\n",
    "        ### THE ENCODER\n",
    "        encoder_input = Input(shape=self.input_dim, name='encoder_input')\n",
    "\n",
    "        x = encoder_input\n",
    "\n",
    "        for i in range(self.n_layers_encoder):\n",
    "            conv_layer = Conv2D(\n",
    "                filters = self.encoder_conv_filters[i]\n",
    "                , kernel_size = self.encoder_conv_kernel_size[i]\n",
    "                , strides = self.encoder_conv_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'encoder_conv_' + str(i)\n",
    "                )\n",
    "\n",
    "            x = conv_layer(x)\n",
    "\n",
    "            x = LeakyReLU()(x)\n",
    "\n",
    "            if self.use_batch_norm:\n",
    "                x = BatchNormalization()(x)\n",
    "\n",
    "            if self.use_dropout:\n",
    "                x = Dropout(rate = 0.25)(x)\n",
    "\n",
    "        shape_before_flattening = K.int_shape(x)[1:]\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        encoder_output= Dense(self.z_dim, name='encoder_output')(x)\n",
    "\n",
    "        self.encoder = Model(encoder_input, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder() :\n",
    "    def __init__(self\n",
    "            , input_dim  # input  값의 형태\n",
    "            , encoder_conv_filters  # 인코더의 convolution layer에서 사용할 필터의 사이즈 \n",
    "            , encoder_conv_kernel_size # 인코더 convolution layer의 커널 사이즈\n",
    "            , encoder_conv_strides\n",
    "                 \n",
    "            , decoder_conv_t_filters # 디코더의 필터\n",
    "            , decoder_conv_t_kernel_size # 디코더 커널 사이즈\n",
    "            , decoder_conv_t_strides # 디코너 stride\n",
    "                 \n",
    "            , z_dim # z의 dim???? 무슨 말이죠\n",
    "            , use_batch_norm = False # Batch Normalzatino 디폴트는 안쓰는걸로 하자\n",
    "            , use_dropout = False # dropout - 과적합 방지를 위해서, 이전 층의 유닛을 랜덤하게 0 으로 만들어버림\n",
    "            ) :\n",
    "        self.name = 'autoencoder'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_size = encoder_conv_kernel_size\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        self.n_layers_encoder = len(encoder_conv_filters)\n",
    "        self.n_layers_decoder = len(decoder_conv_t_filters)\n",
    "        \n",
    "        self._build()\n",
    "        # 일단 만들고 build를 def 단계에서 실행할 껀데 이제 build를 만들어보자\n",
    "        \n",
    "    def _build(self):\n",
    "        \n",
    "        # Encoder 부터 만들어봅시당\n",
    "        encoder_input = Input(shape =self.input_dim, name = 'encoder_input')\n",
    "        \n",
    "        x = encoder_input\n",
    "        \n",
    "        for i in range(self.n_layers_encoder) :# n_layers_encoder 는 encode_conv_filter 의 길이 즉, 여기선 4개의 층\n",
    "            conv_layer = Conv2D(filters = self.encoder_conv_filters[i],\n",
    "                               kernel_size = self.encoder_conv_kernel_size[i],\n",
    "                               strides= self.encoder_conv_strides[i],\n",
    "                               padding = 'same',\n",
    "                               name = 'encoder_conv_'+str(i)\n",
    "                               )\n",
    "            x = conv_layer(x)\n",
    "            x = LeakyReLU()(x)\n",
    "        \n",
    "        #shape_before_flattening = K.int_shape(x)[1:]\n",
    "        # tf 도 같이 사용하고 있으므로 굳이 keras backend 함수 안가져오고, tensorflow 로 처리\n",
    "        shape_before_flattening = tf.shape(x).numpy()[1:]\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        encoder_output = Dense(self.z_dim, name= 'encoder_output')(x)\n",
    "        \n",
    "        # 인코더를 하나의 Model로 만드는 건가\n",
    "        # input과 output 그리고 그걸 계산하는 모든 레이어를 포함한다.\n",
    "        # 미친 기능인거 같다\n",
    "        self.encoder = Model(encoder_input, encoder_output)\n",
    "        \n",
    "        \n",
    "        # Decoder를 만들어봅십당\n",
    "        \n",
    "        decoder_input = Input(shape =(self.z_dim,), name = 'decoder_input')\n",
    "        \n",
    "        # np.prod --> shape_before_flatening : 마지막 Conv2D, LeakyRelu 넘어온애 \n",
    "        # 책에서는 7,7,64 의 각 항들을 곱함 --> 7 * 7* 64\n",
    "        \n",
    "        # 출력층이 7 * 7* 64개의 한 줄인 Dense Layer를 만듬\n",
    "        x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "        \n",
    "        # 다시 x 값을 마지막 Conv2D leakyRelu 넘었던 형태로 reshape\n",
    "        x = Reshape(shape_before_flattening)(x)\n",
    "        \n",
    "        for i in range(self.n_layers_encoder):\n",
    "            conv_t_layer = Conv2DTranspose(\n",
    "            filters = self.decoder_conv_t_filters[i]\n",
    "            , kernel_size = self.decoder_conv_t_kernel_size[i]\n",
    "            , strides = self.decoder_conv_t_strides[i]\n",
    "            ,padding= 'same'\n",
    "            , name = 'decoder_conv_t_'+str(i))\n",
    "            x = conv_t_layer(x)\n",
    "        if i < self.n_layers_decoder - 1 :\n",
    "            x = LeakyReLU(x) # 마지막 놈 전까지는 LeakyRelu 해주고\n",
    "        else :\n",
    "            x = Activation('sigmoid')(x)\n",
    "        \n",
    "        decoder_output = x\n",
    "        \n",
    "        self.decoder = Model(decoder_input, decoder_output)\n",
    "        \n",
    "        \n",
    "        ## encoder와 decoder의 연결\n",
    "        \n",
    "        model_input = encoder_input\n",
    "        model_output = decoder(encoder_output)\n",
    "        self.model = Model(model_input, model_output)\n",
    "        \n",
    "        \n",
    "        # compile - loss function 과 optimizer 연결\n",
    "        def compile(self, learning_rate):\n",
    "            self.learning_rate = learning_rate\n",
    "            \n",
    "            optimizer =Adam(lr=learning_rate)\n",
    "            \n",
    "            # loss는 RMSE(root mean squared  error)사용함 - 크로스엔트로피는 극단적으로 나쁜 예측에 벌칙을 부여--> 픽셀 예측값을 중가\n",
    "            #범위로 만드는 경향 --> 실제 이미지처럼 안보이기 때문에 RMSE 사용해보겠다\n",
    "            \n",
    "            def r_loss(y_true, y_pred):\n",
    "                return tf.keras.backend.mean(tf.math.square(y_true- y_pred), axis =[1,2,3])\n",
    "            \n",
    "            self.model.compile(optimizer=optimizer, loss =r_loss)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input layer\n",
    "### conv + leaky relu * 4\n",
    "### Flatten\n",
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = encoder_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE - Variational AutoEncoder\n",
    "\n",
    "Encoder 는 데이터가 Decoder를 통해 좋은 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
