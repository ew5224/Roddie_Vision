{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE - 변이형 오토인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인코더 - 네트워크는 고차원 입력 데이터를 저차원 표현 벡터로 압축\n",
    "\n",
    "디코더 - 네트워크는 주어진 표현 벡터를 원본 차원으로 다시 압축 해제\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'backend' from 'tensorflow.keras.layers' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\api\\_v2\\keras\\layers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-bee03213da1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'backend' from 'tensorflow.keras.layers' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\api\\_v2\\keras\\layers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교재 Autoencoder\n",
    "\n",
    "class Autoencoder():\n",
    "    def __init__(self\n",
    "        , input_dim\n",
    "        , encoder_conv_filters\n",
    "        , encoder_conv_kernel_size\n",
    "        , encoder_conv_strides\n",
    "        , decoder_conv_t_filters\n",
    "        , decoder_conv_t_kernel_size\n",
    "        , decoder_conv_t_strides\n",
    "        , z_dim\n",
    "        , use_batch_norm = False\n",
    "        , use_dropout = False\n",
    "        ):\n",
    "\n",
    "        self.name = 'autoencoder'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_size = encoder_conv_kernel_size\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        self.n_layers_encoder = len(encoder_conv_filters)\n",
    "        self.n_layers_decoder = len(decoder_conv_t_filters)\n",
    "\n",
    "        self._build()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _build(self):\n",
    "\n",
    "        ### THE ENCODER\n",
    "        encoder_input = Input(shape=self.input_dim, name='encoder_input')\n",
    "\n",
    "        x = encoder_input\n",
    "\n",
    "        for i in range(self.n_layers_encoder):\n",
    "            conv_layer = Conv2D(\n",
    "                filters = self.encoder_conv_filters[i]\n",
    "                , kernel_size = self.encoder_conv_kernel_size[i]\n",
    "                , strides = self.encoder_conv_strides[i]\n",
    "                , padding = 'same'\n",
    "                , name = 'encoder_conv_' + str(i)\n",
    "                )\n",
    "\n",
    "            x = conv_layer(x)\n",
    "\n",
    "            x = LeakyReLU()(x)\n",
    "\n",
    "            if self.use_batch_norm:\n",
    "                x = BatchNormalization()(x)\n",
    "\n",
    "            if self.use_dropout:\n",
    "                x = Dropout(rate = 0.25)(x)\n",
    "\n",
    "        shape_before_flattening = K.int_shape(x)[1:]\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        encoder_output= Dense(self.z_dim, name='encoder_output')(x)\n",
    "\n",
    "        self.encoder = Model(encoder_input, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder() :\n",
    "    def __init__(self\n",
    "            , input_dim  # input  값의 형태\n",
    "            , encoder_conv_filters  # 인코더의 convolution layer에서 사용할 필터의 사이즈 \n",
    "            , encoder_conv_kernel_size # 인코더 convolution layer의 커널 사이즈\n",
    "            , encoder_conv_strides,\n",
    "                 \n",
    "            , decoder_conv_t_filters # 디코더의 필터\n",
    "            , decoder_conv_t_kernel_size # 디코더 커널 사이즈\n",
    "            , decoder_conv_t_strides # 디코너 stride\n",
    "                 \n",
    "            , z_dim # z의 dim???? 무슨 말이죠\n",
    "            , use_batch_norm = False # Batch Normalzatino 디폴트는 안쓰는걸로 하자\n",
    "            , use_dropout = False # dropout - 과적합 방지를 위해서, 이전 층의 유닛을 랜덤하게 0 으로 만들어버림\n",
    "            ) :\n",
    "        self.name = 'autoencoder'\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.encoder_conv_filters = encoder_conv_filters\n",
    "        self.encoder_conv_kernel_size = encoder_conv_kernel_size\n",
    "        self.encoder_conv_strides = encoder_conv_strides\n",
    "        self.decoder_conv_t_filters = decoder_conv_t_filters\n",
    "        self.decoder_conv_t_kernel_size = decoder_conv_t_kernel_size\n",
    "        self.decoder_conv_t_strides = decoder_conv_t_strides\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.use_dropout = use_dropout\n",
    "\n",
    "        self.n_layers_encoder = len(encoder_conv_filters)\n",
    "        \n",
    "        self._build()\n",
    "        # 일단 만들고 build를 def 단계에서 실행할 껀데 이제 build를 만들어보자\n",
    "        \n",
    "    def _build(self):\n",
    "        \n",
    "        # Encoder 부터 만들어봅시당\n",
    "        encoder_input = Input(shape =self.input_dim, name = 'encoder_input')\n",
    "        \n",
    "        x = encoder_input\n",
    "        \n",
    "        for i in range(self.n_layers_encoder) :# n_layers_encoder 는 encode_conv_filter 의 길이 즉, 여기선 4개의 층\n",
    "            conv_layer = Conv2D(filters = self.encoder_conv_filters[i],\n",
    "                               kernel_size = self.encoder_conv_kernel_size[i],\n",
    "                               strides= self.encoder_conv_strides[i],\n",
    "                               padding = 'same',\n",
    "                               name = 'encoder_conv_'+str(i)\n",
    "                               )\n",
    "            x = conv_layer(x)\n",
    "            x = LeakyReLU()(x)\n",
    "        \n",
    "        #shape_before_flattening = K.int_shape(x)[1:]\n",
    "        # tf 도 같이 사용하고 있으므로 굳이 keras backend 함수 안가져오고, tensorflow 로 처리\n",
    "        shape_before_flattening = tf.shape(x).numpy()[1:]\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        encoder_output = Dense(self.z_dim, name= 'encoder_output')(x)\n",
    "        \n",
    "        # 인코더를 하나의 Model로 만드는 건가\n",
    "        # input과 output 그리고 그걸 계산하는 모든 레이어를 포함한다.\n",
    "        # 미친 기능인거 같다\n",
    "        self.encoder = Model(encoder_input, encoder_output)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input layer\n",
    "### conv + leaky relu * 4\n",
    "### Flatten\n",
    "### Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
